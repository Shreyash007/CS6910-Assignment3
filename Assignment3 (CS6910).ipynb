{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dah3sIHW7I8z",
        "outputId": "fde90822-983d-403a-c249-dd6f320fd83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-21 12:52:13--  https://drive.google.com/file/d/1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.130.138, 74.125.130.100, 74.125.130.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.130.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view?usp=sharing’\n",
            "\n",
            "view?usp=sharing        [ <=>                ]  73.93K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-05-21 12:52:14 (6.42 MB/s) - ‘view?usp=sharing’ saved [75702]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!yes | wget \"https://drive.google.com/file/d/1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw/view?usp=sharing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrKhtskRfqcx",
        "outputId": "187ff478-0947-45aa-92dd-c898c0f27fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 21 12:52:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl3oO7Gd7Yi7",
        "outputId": "168a1e6c-a21f-42ee-e706-4358a15c0454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING DATA FROM CSV FILES"
      ],
      "metadata": {
        "id": "5NDoNJFeN5TC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8DUylqRTCSHJ"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    with open(path) as fil:\n",
        "        data = pd.read_csv(fil,sep=',',header=None,names=[\"en\",\"ma\",\"\"],skip_blank_lines=True,index_col=None)\n",
        "    data = data[data['en'].notna()]\n",
        "    data = data[data['ma'].notna()]\n",
        "    data = data[['en','ma']]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drRm1kLlCdXy"
      },
      "outputs": [],
      "source": [
        "\n",
        "train = load_data(\"/content/drive/MyDrive/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv\")\n",
        "val = load_data(\"/content/drive/MyDrive/aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv\")\n",
        "test = load_data(\"/content/drive/MyDrive/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv\")\n",
        "print(test)\n",
        "#below lists are used to save values in CSV again\n",
        "test_en=list(test['en'])\n",
        "test_ma=list(test['ma'])\n",
        "print(test_en)\n",
        "print(test_ma)\n",
        "print(len(train))\n",
        "print(len(test))\n",
        "print(len(val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feSI-Xyl-DM2"
      },
      "source": [
        "#TOKENIZE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3t82UK3kgyF",
        "outputId": "a5051068-7fad-4e6c-f9a8-2068603d5429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "63\n"
          ]
        }
      ],
      "source": [
        "def unique_tokenize(data):\n",
        "    english = train['en'].values\n",
        "    marathi = train['ma'].values\n",
        "    english_tokens = set()\n",
        "    marathi_tokens = set()\n",
        "    \n",
        "    for x,y in zip(english,marathi):\n",
        "        for ch in x:\n",
        "            english_tokens.add(ch)\n",
        "        for ch in y:\n",
        "            marathi_tokens.add(ch)\n",
        "    english_tokens = sorted(list(english_tokens))\n",
        "    marathi_tokens = sorted(list(marathi_tokens))\n",
        "    return marathi_tokens , english_tokens\n",
        "marathi_tokens , english_tokens = unique_tokenize(train)\n",
        "print(english_tokens)\n",
        "print(len(marathi_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_pt0sC09-AE"
      },
      "source": [
        "#TOKEN MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeeJVQ2EjRqO",
        "outputId": "2b5de9b9-6673-4f4c-e90e-a3722d9f8aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ँ': 1, 'ं': 2, 'ः': 3, 'अ': 4, 'आ': 5, 'इ': 6, 'ई': 7, 'उ': 8, 'ऊ': 9, 'ऋ': 10, 'ऍ': 11, 'ए': 12, 'ऐ': 13, 'ऑ': 14, 'ओ': 15, 'औ': 16, 'क': 17, 'ख': 18, 'ग': 19, 'घ': 20, 'च': 21, 'छ': 22, 'ज': 23, 'झ': 24, 'ञ': 25, 'ट': 26, 'ठ': 27, 'ड': 28, 'ढ': 29, 'ण': 30, 'त': 31, 'थ': 32, 'द': 33, 'ध': 34, 'न': 35, 'प': 36, 'फ': 37, 'ब': 38, 'भ': 39, 'म': 40, 'य': 41, 'र': 42, 'ल': 43, 'ळ': 44, 'व': 45, 'श': 46, 'ष': 47, 'स': 48, 'ह': 49, '़': 50, 'ा': 51, 'ि': 52, 'ी': 53, 'ु': 54, 'ू': 55, 'ृ': 56, 'ॅ': 57, 'े': 58, 'ै': 59, 'ॉ': 60, 'ो': 61, 'ौ': 62, '्': 63, ' ': 0, ';': 65, '.': 66, '<unk>': 64}\n",
            "{1: 'ँ', 2: 'ं', 3: 'ः', 4: 'अ', 5: 'आ', 6: 'इ', 7: 'ई', 8: 'उ', 9: 'ऊ', 10: 'ऋ', 11: 'ऍ', 12: 'ए', 13: 'ऐ', 14: 'ऑ', 15: 'ओ', 16: 'औ', 17: 'क', 18: 'ख', 19: 'ग', 20: 'घ', 21: 'च', 22: 'छ', 23: 'ज', 24: 'झ', 25: 'ञ', 26: 'ट', 27: 'ठ', 28: 'ड', 29: 'ढ', 30: 'ण', 31: 'त', 32: 'थ', 33: 'द', 34: 'ध', 35: 'न', 36: 'प', 37: 'फ', 38: 'ब', 39: 'भ', 40: 'म', 41: 'य', 42: 'र', 43: 'ल', 44: 'ळ', 45: 'व', 46: 'श', 47: 'ष', 48: 'स', 49: 'ह', 50: '़', 51: 'ा', 52: 'ि', 53: 'ी', 54: 'ु', 55: 'ू', 56: 'ृ', 57: 'ॅ', 58: 'े', 59: 'ै', 60: 'ॉ', 61: 'ो', 62: 'ौ', 63: '्', 64: '<unk>', 65: ';', 66: '.', 0: ''}\n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, ' ': 0, ';': 27, '.': 28}\n",
            "mar: 67\n",
            "eng: 29\n"
          ]
        }
      ],
      "source": [
        "#REWRITE AGAIN\n",
        "def tokenize_map(hindi_tokens , english_tokens):\n",
        "    english_token_map = dict([(ch,i+1) for i,ch in enumerate(english_tokens)])\n",
        "    marathi_token_map = dict([(ch,i+1) for i,ch in enumerate(marathi_tokens)])\n",
        "    reverse_marathi_token_map = dict([(i+1,ch) for i,ch in enumerate(marathi_tokens)])\n",
        "    #Adding blank space\n",
        "\n",
        "    marathi_token_map[\" \"] = 0\n",
        "    english_token_map[\" \"] = 0\n",
        "    #addin BOS and EOS token \n",
        "    marathi_token_map[';']=65\n",
        "    marathi_token_map['.']=66\n",
        "    english_token_map[';']=27\n",
        "    english_token_map['.']=28\n",
        "    marathi_token_map['<unk>']=64\n",
        "    \n",
        "    reverse_marathi_token_map[64]='<unk>'\n",
        "    reverse_marathi_token_map[65]=';'\n",
        "    reverse_marathi_token_map[66]='.'\n",
        "    reverse_marathi_token_map[0]=''\n",
        "\n",
        "    return marathi_token_map, english_token_map,reverse_marathi_token_map\n",
        "\n",
        "mar_token_map, eng_token_map,reverse_marathi_token_map = tokenize_map(marathi_tokens , english_tokens)\n",
        "print(mar_token_map)\n",
        "print(reverse_marathi_token_map)\n",
        "print(eng_token_map)\n",
        "\n",
        "print('mar:',len(mar_token_map))\n",
        "print('eng:',len(eng_token_map))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOOqbrfKo-ks"
      },
      "source": [
        "#MAXIMUM WORD LENGTH THAT ARE PRESENT IN THE DATASET\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aMkFt73o-IW",
        "outputId": "ab6a2141-8fb1-4167-985d-2693cd06d1a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 22\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = test['en'].values\n",
        "y = test['ma'].values\n",
        "x=';'+ x + '.'\n",
        "y = ';'+y+'.'\n",
        "#Getting max length\n",
        "max_eng_len = max([len(i) for i in x])\n",
        "max_mar_len = max([len(i) for i in y])\n",
        "print(max_eng_len,max_mar_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-ry8u0ousdZ"
      },
      "source": [
        "# ONE HOT ENCODING/EMBEDDING OUR INPUT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdffrLwysNo-",
        "outputId": "0f61f3f7-1140-4de5-a547-90f9019972c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[';fusharun.' ';bhulthapana.' ';vhayaki.']\n",
            "[';फुशारुन.' ';भूलथापाना.' ';व्हायकी.']\n",
            "torch.Size([51200, 30])\n",
            "torch.Size([51200, 30])\n",
            "torch.Size([51200, 30])\n",
            "[';garvyabarobarach.' ';reo.' ';sangrahalaye.']\n",
            "[';गारव्याबरोबरच.' ';रियो.' ';संग्रहालये.']\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "[';heetler.' ';kshama.' ';jinkta.']\n",
            "[';हिटलर.' ';क्षमा.' ';जिंकता.']\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "\n",
            "\n",
            "num of rows: 51200\n",
            "num of columns: 2\n",
            "tensor([65, 37, 54, 46, 51, 42, 54, 35, 66,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "#unknown token present in validation set as 'r.(in marathi)'\n",
        "unknown_token=64\n",
        "def process(data):\n",
        "    x,y = data['en'].values, data['ma'].values\n",
        "    x = \";\" + x + \".\"\n",
        "    y = \";\" + y + \".\"\n",
        "    print(x[0:3])\n",
        "    print(y[0:3]) \n",
        "    \n",
        "    a = torch.zeros((len(x),max_eng_len),dtype=torch.int64)\n",
        "    print(a.shape)\n",
        "    \n",
        "    b = torch.zeros((len(y),max_eng_len),dtype=torch.int64)\n",
        "    \n",
        "    data=[]\n",
        "    for i,(xx,yy) in enumerate(zip(x,y)):\n",
        "        for j,ch in enumerate(xx):\n",
        "            a[i,j] = eng_token_map[ch]\n",
        "\n",
        "        #a[i,j+1:] = eng_token_map[\" \"]\n",
        "        for j,ch in enumerate(yy):\n",
        "            if ch in mar_token_map: \n",
        "             b[i,j] = mar_token_map[ch]\n",
        "            else:\n",
        "              b[i,j]= unknown_token\n",
        "\n",
        "\n",
        "    data = [(a[i], b[i]) for i in range(len(x))]\n",
        "    print(a.shape)\n",
        "    print(b.shape)\n",
        "    return data\n",
        "\n",
        "train_process=process(train)\n",
        "val_process=process(val)\n",
        "test_process=process(test)\n",
        "#print(train_process.shape)\n",
        "print('\\n')\n",
        "print('num of rows:',len(train_process))\n",
        "print('num of columns:',len(train_process[0]))\n",
        "print(train_process[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w61HFE3F2aol",
        "outputId": "3bec134a-d2b0-43cc-968b-8109d11a3919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ";फुशारुन.\n"
          ]
        }
      ],
      "source": [
        "#Used later for reading the words\n",
        "\n",
        "from torch import tensor\n",
        "def reverse_tokenize(data):\n",
        "  data=[int(i) for i in data]\n",
        "  predicted_seq = [reverse_marathi_token_map[idx] for idx in data]\n",
        "  predicted_seq=''.join(predicted_seq)\n",
        "  return predicted_seq\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wDRhKZ4-LHs"
      },
      "source": [
        "#DATA LOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1SvwaaN-Lj9",
        "outputId": "29549e79-d2c1-4489-912a-5b2d7b3f8856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n",
            "256\n",
            "256\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "PAD_IDX = 0\n",
        "BOS_IDX = ';'\n",
        "EOS_IDX = '.'\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#WE ARE NOT USING GENERATE BATCH FUNCTION\n",
        "def generate_batch(data_batch):\n",
        "  ma_batch, en_batch = [], []\n",
        "  for (en_item,ma_item) in data_batch:\n",
        "    #ma_batch.append(torch.cat([torch.tensor(mar_token_map[BOS_IDX]), ma_item, torch.tensor(mar_token_map[EOS_IDX])], dim=0))\n",
        "    #en_batch.append(torch.cat([torch.tensor(eng_token_map[BOS_IDX]), en_item, torch.tensor(eng_token_map[EOS_IDX])], dim=0))\n",
        "    #print(ma_item[0])\n",
        "    ma_batch=torch.tensor(ma_item,dtype=torch.int64)\n",
        "    en_batch=torch.tensor(en_item,dtype=torch.int64)\n",
        "  \n",
        "  return  en_batch.to(device),ma_batch.to(device)\n",
        "\n",
        "\n",
        "\n",
        "train_iter = DataLoader(train_process, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False)\n",
        "valid_iter = DataLoader(val_process, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False)\n",
        "test_iter = DataLoader(test_process, batch_size=BATCH_SIZE,\n",
        "                       shuffle=False)\n",
        "print(len(train_iter))\n",
        "print(len(test_iter))\n",
        "print(len(valid_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "547j1j6T2bEu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import string\n",
        "import random\n",
        "from collections import Counter\n",
        "# Set random seed for reproducibility\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "import os\n",
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "#os.environ['TORCH_USE_CUDA_DSA'] = '1'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login aa5afea12b4fda1e7f8310b597eb17c73d1176d2 #my API key for wandb login \n",
        "import wandb"
      ],
      "metadata": {
        "id": "rnhhFib9Vrl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0GVbIJUNEds"
      },
      "source": [
        "#ATTENTION MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HnpQyXnNBh0",
        "outputId": "b6464bca-120d-40d2-be6f-12a87adb9169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,630,467 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        #print('inp. dim')\n",
        "        #print(self.input_dim)\n",
        "        #print('emb. dim')\n",
        "        #print(self.emb_dim)\n",
        "        self.embedding = nn.Embedding(self.input_dim, self.emb_dim)\n",
        "        \n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "        src = src.permute(1,0)\n",
        "        #print(src)\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "        input = input.permute(1,0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        #print(weighted_encoder_rep.shape)\n",
        "        embedded = embedded.permute(1,0,2)\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        max_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        #ATTENTION HEAT MAP METHOD\n",
        "        #attentions = torch.zeros(max_len, batch_size, src.shape[1]).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        trg = trg.permute(1,0)\n",
        "        output = trg[0,:]\n",
        "        \n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(eng_token_map)\n",
        "OUTPUT_DIM = len(mar_token_map)\n",
        "ENC_EMB_DIM = 512\n",
        "DEC_EMB_DIM = 512\n",
        "ENC_HID_DIM = 256\n",
        "DEC_HID_DIM = 256\n",
        "ATTN_DIM = 256\n",
        "ENC_DROPOUT = 0.3\n",
        "DEC_DROPOUT = 0.3\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "#added custom weights\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ATTENTION WANDB IMPLEMENTATION"
      ],
      "metadata": {
        "id": "QP2vxY5EIul0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "sweep_config = {\n",
        "    'method': 'bayes', #grid, random,bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'  \n",
        "    },\n",
        "    'parameters': {\n",
        "        'emb_dim': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "        'hidden_layer_dim': {\n",
        "            'values': [128,256,512]\n",
        "        },        \n",
        "        'attn_dim':{\n",
        "            'values':[64,128,256]\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0.3,0.5,0.6]\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='shreyashgadgil007', project=\"CS6910-Assignment3\")\n",
        "\n",
        "def sweep_train():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults = {\n",
        "      'emb_dim':256,\n",
        "      'hidden_layer_dim':256,\n",
        "      'attn_dim':128,\n",
        "      'dropout':0.6,\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(project='CS6910-Assignment3', entity='shreyashgadgil007',config=config_defaults)\n",
        "  wandb.run.name = 'emb_dim:'+ str(wandb.config.emb_dim)+' ;hl:'+str(wandb.config.hidden_layer_dim)+ ' ;attn_dim:'+str(wandb.config.attn_dim)+ ' ;dropout:'+str(wandb.config.dropout)\n",
        "  config = wandb.config\n",
        "  emb_dim = config.emb_dim\n",
        "  hidden_layer_dim = config.hidden_layer_dim\n",
        "  attn_dim = config.attn_dim\n",
        "  dropout = config.dropout\n",
        "  # Model training here\n",
        "\n",
        "  INPUT_DIM = len(eng_token_map)\n",
        "  OUTPUT_DIM = len(mar_token_map)\n",
        "\n",
        "  enc = Encoder(INPUT_DIM, emb_dim, hidden_layer_dim, hidden_layer_dim, dropout)\n",
        "\n",
        "  attn = Attention(hidden_layer_dim, hidden_layer_dim, attn_dim)\n",
        "\n",
        "  dec = Decoder(OUTPUT_DIM, emb_dim, hidden_layer_dim, hidden_layer_dim, dropout, attn)\n",
        "\n",
        "  model = Seq2Seq(enc, dec, device).to(device)\n",
        "  model.apply(init_weights)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "  val_epoch_loss = 0\n",
        "  val_epoch_acc = 0\n",
        "  \n",
        "  N_EPOCHS = 10\n",
        "  CLIP = 1\n",
        "\n",
        "  for epoch in range(N_EPOCHS):\n",
        "\n",
        "  #TRAINING BLOCK\n",
        "    model.train()\n",
        "    for _, (src, trg) in enumerate(train_iter):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg.permute(1,0)\n",
        "        trg = torch.reshape(trg[1:], (-1,))\n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        train_correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        train_epoch_acc += train_correct.sum().item() / len(non_pad_elements)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    train_epoch_loss = train_epoch_loss / len(train_iter)\n",
        "    train_epoch_acc = train_epoch_acc / len(train_iter)\n",
        "\n",
        "\n",
        "    #EVALUATION MODE\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(valid_iter):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg.permute(1,0)\n",
        "            trg = torch.reshape(trg[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            val_epoch_loss += loss.item()\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            val_correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            val_epoch_acc += val_correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "    val_epoch_loss = val_epoch_loss / len(valid_iter)\n",
        "    val_epoch_acc = val_epoch_acc / len(valid_iter)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} |Train Loss: {train_epoch_loss:.3f} | Train accuracy: {train_epoch_acc:.3f}|Val. Loss: {val_epoch_loss:.3f} | Val accuracy: {val_epoch_acc:.3f}')\n",
        "    wandb.log({\"train_loss\":train_epoch_loss,\"train_accuracy\": train_epoch_acc,\"val_loss\":val_epoch_loss,\"val_accuracy\":val_epoch_acc},)\n",
        "    #emptying the cache after one complete run\n",
        "    if epoch==N_EPOCHS-1:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "#RUNNING THE SWEEP\n",
        "wandb.agent(sweep_id, function=sweep_train, count=120)"
      ],
      "metadata": {
        "id": "KwA5nEgVItcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VANILLA SEQ2SEQ MODEL"
      ],
      "metadata": {
        "id": "Q87S_hH5PKID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AXjK_20QAQp",
        "outputId": "1251866f-44ff-4a8d-ae3a-c7739f75930c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 3m 35s\n",
            "\tTrain Loss: 0.845 | Train accuracy: 0.386\n",
            "\t Val. Loss: 0.590 | Val accuracy: 0.492\n",
            "गर्वायाबरोबररच.\n",
            "Epoch: 02 | Time: 3m 35s\n",
            "\tTrain Loss: 0.333 | Train accuracy: 0.739\n",
            "\t Val. Loss: 0.445 | Val accuracy: 0.647\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 03 | Time: 3m 38s\n",
            "\tTrain Loss: 0.234 | Train accuracy: 0.817\n",
            "\t Val. Loss: 0.415 | Val accuracy: 0.687\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 04 | Time: 3m 38s\n",
            "\tTrain Loss: 0.207 | Train accuracy: 0.839\n",
            "\t Val. Loss: 0.410 | Val accuracy: 0.699\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 05 | Time: 3m 37s\n",
            "\tTrain Loss: 0.193 | Train accuracy: 0.851\n",
            "\t Val. Loss: 0.413 | Val accuracy: 0.706\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 06 | Time: 3m 33s\n",
            "\tTrain Loss: 0.182 | Train accuracy: 0.860\n",
            "\t Val. Loss: 0.403 | Val accuracy: 0.705\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 07 | Time: 3m 29s\n",
            "\tTrain Loss: 0.174 | Train accuracy: 0.866\n",
            "\t Val. Loss: 0.428 | Val accuracy: 0.712\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 08 | Time: 3m 29s\n",
            "\tTrain Loss: 0.173 | Train accuracy: 0.868\n",
            "\t Val. Loss: 0.426 | Val accuracy: 0.704\n",
            "गारव्याबरोबरच.\n",
            "Epoch: 09 | Time: 3m 32s\n",
            "\tTrain Loss: 0.172 | Train accuracy: 0.869\n",
            "\t Val. Loss: 0.420 | Val accuracy: 0.709\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 10 | Time: 3m 29s\n",
            "\tTrain Loss: 0.171 | Train accuracy: 0.870\n",
            "\t Val. Loss: 0.416 | Val accuracy: 0.711\n",
            "गरव्याबरोबरच.\n",
            "| Test Loss: 0.522 | Test accuracy: 0.669 |\n"
          ]
        }
      ],
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: torch.utils.data.DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_word_acc = 0\n",
        "    total_chars = 0\n",
        "    correct_chars = 0\n",
        "    total_words = 0\n",
        "    correct_words = 0\n",
        "\n",
        "\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg.permute(1,0)\n",
        "        trg = torch.reshape(trg[1:], (-1,))\n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        # calculate character level accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        epoch_acc += correct.sum().item() / len(non_pad_elements)\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: torch.utils.data.DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_word_acc = 0\n",
        "    total_chars = 0\n",
        "    correct_chars = 0\n",
        "    total_words = 0\n",
        "    correct_words = 0\n",
        "    solution=[]\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg.permute(1,0)\n",
        "            trg = torch.reshape(trg[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            epoch_acc += correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "            b=np.zeros((16,29))\n",
        "            for i in range(16):\n",
        "              for j in range (29):\n",
        "                 b[i][j]=preds[16*j+i]\n",
        "            \n",
        "            for i in range(16):\n",
        "              solution.append(reverse_tokenize(b[i]))\n",
        "\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), solution\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss,train_acc = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss,val_acc,solution_valid = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train accuracy: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val accuracy: {val_acc:.3f}')\n",
        "    print(solution_valid[0])\n",
        "\n",
        "test_loss,test_accuracy,solution_test_att = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test accuracy: {test_accuracy:.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY7YZLIzNCNv"
      },
      "source": [
        "#VANILLA SEQ2SEQ MODEL ON TEST DATASET\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HJTv3GZ1DHI5"
      },
      "outputs": [],
      "source": [
        "# Define the vocabulary of English and Devanagari characters\n",
        "\n",
        "# Define the maximum sequence lengths for input and output sequences\n",
        "MAX_LEN_EN = 30\n",
        "MAX_LEN_MA = 30\n",
        "\n",
        "# Define the start and end of sequence tokens\n",
        "BOS_token = 28\n",
        "EOS_token = 29\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1 , cell_type=\"lstm\", p=0.5):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell_type=cell_type\n",
        "        self.dropout=nn.Dropout(p)\n",
        "        self.embedding = nn.Embedding(input_size,embedding_size)\n",
        "\n",
        "        if cell_type == \"gru\":\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, num_layers,dropout=p)\n",
        "        elif cell_type == \"lstm\":\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers,dropout=p)\n",
        "        elif cell_type == \"rnn\":\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, num_layers,dropout=p)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type selected: {}\".format(cell_type))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x=x.permute(1,0)\n",
        "        embedding=self.dropout(self.embedding(x))\n",
        "        if self.cell_type==\"lstm\":\n",
        "         outputs,(hidden,cell)=self.rnn(embedding)\n",
        "        else:\n",
        "           hidden, cell = self.rnn(embedding)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1, cell_type=\"lstm\",p=0.5):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout=nn.Dropout(p)\n",
        "        self.embedding=nn.Embedding(input_size, embedding_size)\n",
        "        self.cell_type=cell_type\n",
        "\n",
        "        self.output_size = output_size\n",
        "        if cell_type == \"gru\":\n",
        "            self.rnn = nn.GRU(output_size, hidden_size, num_layers)\n",
        "        elif cell_type == \"lstm\":\n",
        "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers,dropout=p)\n",
        "        elif cell_type == \"rnn\":\n",
        "            self.rnn = nn.RNN(output_size, hidden_size, num_layers)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type selected: {}\".format(cell_type))\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden,cell):\n",
        "       # shape of x: (N) but we want (1,N)\n",
        "       x=x.unsqueeze(0)\n",
        "\n",
        "       embedding= self.dropout(self.embedding(x))\n",
        "       #embedding shape: (1,N,hidden_size)\n",
        "       \n",
        "       if self.cell_type==\"lstm\":\n",
        "        outputs,(hidden,cell) = self.rnn(embedding, (hidden,cell))\n",
        "       else:\n",
        "         outputs, hidden = self.rnn(embedding, hidden)\n",
        "       #shape of outputs: (1,N,hidden_size)\n",
        "       \n",
        "\n",
        "       predictions=self.fc(outputs)\n",
        "       #shape of predictions: (1,N,length_of_vocab)\n",
        "\n",
        "       predictions = predictions.squeeze(0)\n",
        "       \n",
        "       if self.cell_type==\"lstm\":\n",
        "         return predictions, hidden, cell\n",
        "       else:\n",
        "         return predictions, hidden\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(\n",
        "        self,encoder,decoder,cell_type=\"lstm\"):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[0]\n",
        "        \n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size=self.decoder.output_size\n",
        "\n",
        "        outputs=torch.zeros(target_len,batch_size,target_vocab_size).to(device)\n",
        "        \n",
        "        cell,hidden=self.encoder(source)\n",
        "        \n",
        "        target = target.permute(1,0)\n",
        "        x = target[0,:]\n",
        "        for t in range(1,target_len):\n",
        "          if self.cell_type==\"lstm\":\n",
        "           output,hidden,cell =self.decoder(x,hidden,cell)\n",
        "          else:\n",
        "            output, hidden = self.decoder(x,hidden,cell)\n",
        "\n",
        "          outputs[t] = output\n",
        "          \n",
        "          best_guess = output.argmax(1)\n",
        "\n",
        "          x= target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP3feLygxyV0",
        "outputId": "9952f40c-9fa0-4a06-ae62-016eac85a9b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 2m 28s\n",
            "\tTrain Loss: 0.732 | Train accuracy: 0.470\n",
            "\t Val. Loss: 0.509 | Val accuracy: 0.578\n",
            "गर्व्याबरोबरच.\n",
            "Epoch: 02 | Time: 2m 30s\n",
            "\tTrain Loss: 0.339 | Train accuracy: 0.732\n",
            "\t Val. Loss: 0.466 | Val accuracy: 0.633\n",
            "गर्व्याबरोबरच.\n",
            "Epoch: 03 | Time: 2m 30s\n",
            "\tTrain Loss: 0.274 | Train accuracy: 0.783\n",
            "\t Val. Loss: 0.433 | Val accuracy: 0.668\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 04 | Time: 2m 29s\n",
            "\tTrain Loss: 0.248 | Train accuracy: 0.803\n",
            "\t Val. Loss: 0.407 | Val accuracy: 0.687\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 05 | Time: 2m 30s\n",
            "\tTrain Loss: 0.231 | Train accuracy: 0.817\n",
            "\t Val. Loss: 0.427 | Val accuracy: 0.693\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 06 | Time: 2m 29s\n",
            "\tTrain Loss: 0.221 | Train accuracy: 0.825\n",
            "\t Val. Loss: 0.419 | Val accuracy: 0.698\n",
            "गर््यावरोबरच.\n",
            "Epoch: 07 | Time: 2m 30s\n",
            "\tTrain Loss: 0.217 | Train accuracy: 0.829\n",
            "\t Val. Loss: 0.417 | Val accuracy: 0.703\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 08 | Time: 2m 31s\n",
            "\tTrain Loss: 0.213 | Train accuracy: 0.832\n",
            "\t Val. Loss: 0.416 | Val accuracy: 0.702\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 09 | Time: 2m 30s\n",
            "\tTrain Loss: 0.212 | Train accuracy: 0.832\n",
            "\t Val. Loss: 0.419 | Val accuracy: 0.690\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 10 | Time: 2m 30s\n",
            "\tTrain Loss: 0.214 | Train accuracy: 0.832\n",
            "\t Val. Loss: 0.420 | Val accuracy: 0.695\n",
            "गरव्याबरोबरच.\n",
            "| Test Loss: 0.511 | Test accuracy:   0.656 |\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "num_epochs=10\n",
        "learning_rate=0.001\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "input_size_encoder = len(eng_token_map)\n",
        "input_size_decoder=len(mar_token_map)\n",
        "output_size=len(mar_token_map)\n",
        "\n",
        "encoder_embedding_size=29\n",
        "decoder_embedding_size=67\n",
        "\n",
        "cell_type=\"gru\"\n",
        "hidden_size=256\n",
        "num_layers=4\n",
        "enc_dropout=0.2\n",
        "dec_dropout=0.2\n",
        "#input_size, embedding_size, hidden_size, num_layers=1 , cell_type=\"lstm\", p=0.5\n",
        "encoder_net=Encoder(input_size_encoder,encoder_embedding_size,hidden_size,num_layers,cell_type,p=enc_dropout).to(device)\n",
        "decoder_net=Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_size,num_layers,cell_type,p=dec_dropout).to(device)\n",
        "model=Seq2Seq(encoder_net,decoder_net,cell_type).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "import math\n",
        "import time\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "def train(model: nn.Module,\n",
        "          iterator: torch.utils.data.DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg.permute(1,0)\n",
        "        trg = torch.reshape(trg[1:], (-1,))\n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        epoch_acc += correct.sum().item() / len(non_pad_elements)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: torch.utils.data.DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "    solution=[]\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            \n",
        "            trg = trg.permute(1,0)\n",
        "            trg = torch.reshape(trg[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            b=np.zeros((16,29))\n",
        "            for i in range(16):\n",
        "              for j in range (29):\n",
        "                 b[i][j]=preds[16*j+i]\n",
        "            \n",
        "            for i in range(16):\n",
        "              solution.append(reverse_tokenize(b[i]))\n",
        "            non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            epoch_acc += correct.sum().item() / len(non_pad_elements)\n",
        "            \n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator),solution\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss,train_acc = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss,val_acc,solution = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train accuracy: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val accuracy: {val_acc:.3f}')\n",
        "    print(solution[0])\n",
        "\n",
        "\n",
        "test_loss,test_accuracy,solution_test = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test accuracy: {test_accuracy:7.3f} |')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-OQ0gNbMY08"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install --upgrade wandb\n",
        "!wandb login aa5afea12b4fda1e7f8310b597eb17c73d1176d2 #my API key for wandb login \n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WANDB IMPLEMENTATION"
      ],
      "metadata": {
        "id": "TJF-7OZJSpNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4149a4c78e664d71a256e6deaab7716d",
            "3f8878c3e01f4dfe954752b6a726974c",
            "2fb0c0dc7f564ad5849f01201a2349dc",
            "3726b5cd9ab240f198b0abf2bd0ee999",
            "5cffdb42030b4aaaa4adf32ed67a4bd0",
            "d490c128677e486981c7ed932e7a8e4a",
            "fafea03cb3874a209280303fd0ac44e5",
            "66c1662f065e4171803abdb4210d4df0",
            "3cb5d0076b4e4ce8bf8943a44895bdc6",
            "ee966b1121cd45c28893b2cc3a0f36ef",
            "1e20596ffc514c82b89c308c78e60097",
            "09dc089336be4b8a9fb06ebd4e27b92e",
            "c269d71a857e408aa28d91b2efd35eff",
            "1c4c5300439a47fca5d0dc2bbb00c7c5",
            "009d917192ac45f8b9a5cb3e88b3be67",
            "99445299e74d4e7db3951662a977c21a",
            "d2c4d6f23f594ef3b9bb9514eb986abb",
            "62351b579cad492bafe79bec945e8327",
            "62cdf5406f4f4ae0bfef029acc8b25ac",
            "770c3cb14d53452296ae96b6d12acb2b",
            "3fa2e79d8bf645fd925b2ca74b33ace1",
            "2de8fbf1431348c0b375c2bea37bc58a",
            "0029bd3ca1c94350a4ed311349e040bf",
            "99b20e257eb94f7c9ea138b138b8b92a",
            "e8e252f6d5d141bba53ec2757bbb498f",
            "ed6fb297d7cb4188953724e8fd678c56",
            "d0e13e633f6c46749d354d038df3dfff",
            "2f6b8df6ebb44ab1b38f5aebd30225d5",
            "4db95218bd8c45fd8638e73b17655541",
            "c4204db901f44e57a468b949be7a9cc5",
            "4562bbd5ab014f7084a5b74100662d6c",
            "4e3528158aaf4a6687bdeb93fd7164d3"
          ]
        },
        "id": "L4DAr9DwEqcX",
        "outputId": "e8fec47b-d42d-477b-bc73-4ac4533b4cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._resume_backend at 0x7ffaa83481f0> (for pre_run_cell):\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: t1x3tqqp\n",
            "Sweep URL: https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rfsh9ynk with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4149a4c78e664d71a256e6deaab7716d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669342216664516, max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230516_134057-rfsh9ynk</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/rfsh9ynk' target=\"_blank\">vibrant-sweep-1</a></strong> to <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/rfsh9ynk' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/rfsh9ynk</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 |Train Loss: 1.255 | Train accuracy: 0.168|Val. Loss: 1.302 | Val accuracy: 0.102\n",
            "Epoch: 02 |Train Loss: 1.172 | Train accuracy: 0.197|Val. Loss: 1.276 | Val accuracy: 0.113\n",
            "Epoch: 03 |Train Loss: 1.155 | Train accuracy: 0.205|Val. Loss: 1.221 | Val accuracy: 0.108\n",
            "Epoch: 04 |Train Loss: 1.145 | Train accuracy: 0.210|Val. Loss: 1.209 | Val accuracy: 0.108\n",
            "Epoch: 05 |Train Loss: 1.139 | Train accuracy: 0.213|Val. Loss: 1.212 | Val accuracy: 0.108\n",
            "Epoch: 06 |Train Loss: 1.132 | Train accuracy: 0.216|Val. Loss: 1.253 | Val accuracy: 0.092\n",
            "Epoch: 07 |Train Loss: 1.130 | Train accuracy: 0.217|Val. Loss: 1.252 | Val accuracy: 0.106\n",
            "Epoch: 08 |Train Loss: 1.125 | Train accuracy: 0.220|Val. Loss: 1.289 | Val accuracy: 0.115\n",
            "Epoch: 09 |Train Loss: 1.122 | Train accuracy: 0.222|Val. Loss: 1.216 | Val accuracy: 0.108\n",
            "Epoch: 10 |Train Loss: 1.118 | Train accuracy: 0.224|Val. Loss: 1.248 | Val accuracy: 0.103\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cb5d0076b4e4ce8bf8943a44895bdc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.110128…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▅▆▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▄▇▆▆▆▁▅█▆▄</td></tr><tr><td>val_loss</td><td>█▆▂▁▁▄▄▇▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.22405</td></tr><tr><td>train_loss</td><td>1.11841</td></tr><tr><td>val_accuracy</td><td>0.10258</td></tr><tr><td>val_loss</td><td>1.24847</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vibrant-sweep-1</strong> at: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/rfsh9ynk' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/rfsh9ynk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230516_134057-rfsh9ynk/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wv6r2hz6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230516_135520-wv6r2hz6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/wv6r2hz6' target=\"_blank\">jumping-sweep-2</a></strong> to <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/wv6r2hz6' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/wv6r2hz6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 |Train Loss: 1.398 | Train accuracy: 0.123|Val. Loss: 0.996 | Val accuracy: 0.144\n",
            "Epoch: 02 |Train Loss: 1.183 | Train accuracy: 0.170|Val. Loss: 0.986 | Val accuracy: 0.146\n",
            "Epoch: 03 |Train Loss: 1.135 | Train accuracy: 0.201|Val. Loss: 0.981 | Val accuracy: 0.148\n",
            "Epoch: 04 |Train Loss: 1.112 | Train accuracy: 0.211|Val. Loss: 0.977 | Val accuracy: 0.152\n",
            "Epoch: 05 |Train Loss: 1.095 | Train accuracy: 0.219|Val. Loss: 0.962 | Val accuracy: 0.160\n",
            "Epoch: 06 |Train Loss: 1.074 | Train accuracy: 0.231|Val. Loss: 0.948 | Val accuracy: 0.173\n",
            "Epoch: 07 |Train Loss: 1.055 | Train accuracy: 0.242|Val. Loss: 0.937 | Val accuracy: 0.181\n",
            "Epoch: 08 |Train Loss: 1.034 | Train accuracy: 0.253|Val. Loss: 0.916 | Val accuracy: 0.184\n",
            "Epoch: 09 |Train Loss: 1.016 | Train accuracy: 0.263|Val. Loss: 0.913 | Val accuracy: 0.202\n",
            "Epoch: 10 |Train Loss: 1.001 | Train accuracy: 0.272|Val. Loss: 0.893 | Val accuracy: 0.209\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2c4d6f23f594ef3b9bb9514eb986abb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▃▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▂▃▄▅▅▇█</td></tr><tr><td>val_loss</td><td>█▇▇▇▆▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.27166</td></tr><tr><td>train_loss</td><td>1.00125</td></tr><tr><td>val_accuracy</td><td>0.2085</td></tr><tr><td>val_loss</td><td>0.89289</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">jumping-sweep-2</strong> at: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/wv6r2hz6' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/wv6r2hz6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230516_135520-wv6r2hz6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vv0njss1 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230516_141231-vv0njss1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/vv0njss1' target=\"_blank\">likely-sweep-3</a></strong> to <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/vv0njss1' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/vv0njss1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 |Train Loss: 1.211 | Train accuracy: 0.168|Val. Loss: 0.943 | Val accuracy: 0.168\n",
            "Epoch: 02 |Train Loss: 1.047 | Train accuracy: 0.245|Val. Loss: 0.866 | Val accuracy: 0.246\n",
            "Epoch: 03 |Train Loss: 0.899 | Train accuracy: 0.334|Val. Loss: 0.730 | Val accuracy: 0.353\n",
            "Epoch: 04 |Train Loss: 0.745 | Train accuracy: 0.439|Val. Loss: 0.654 | Val accuracy: 0.434\n",
            "Epoch: 05 |Train Loss: 0.626 | Train accuracy: 0.522|Val. Loss: 0.581 | Val accuracy: 0.489\n",
            "Epoch: 06 |Train Loss: 0.542 | Train accuracy: 0.582|Val. Loss: 0.550 | Val accuracy: 0.530\n",
            "Epoch: 07 |Train Loss: 0.477 | Train accuracy: 0.628|Val. Loss: 0.522 | Val accuracy: 0.559\n",
            "Epoch: 08 |Train Loss: 0.423 | Train accuracy: 0.667|Val. Loss: 0.501 | Val accuracy: 0.589\n",
            "Epoch: 09 |Train Loss: 0.385 | Train accuracy: 0.696|Val. Loss: 0.474 | Val accuracy: 0.612\n",
            "Epoch: 10 |Train Loss: 0.350 | Train accuracy: 0.723|Val. Loss: 0.459 | Val accuracy: 0.635\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▅▄▃▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▅▆▆▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.72308</td></tr><tr><td>train_loss</td><td>0.34973</td></tr><tr><td>val_accuracy</td><td>0.63526</td></tr><tr><td>val_loss</td><td>0.45895</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">likely-sweep-3</strong> at: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/vv0njss1' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/vv0njss1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230516_141231-vv0njss1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9apz8ryn with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230516_143633-9apz8ryn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/9apz8ryn' target=\"_blank\">treasured-sweep-4</a></strong> to <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/9apz8ryn' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/9apz8ryn</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 |Train Loss: 1.236 | Train accuracy: 0.157|Val. Loss: 0.971 | Val accuracy: 0.161\n",
            "Epoch: 02 |Train Loss: 1.083 | Train accuracy: 0.225|Val. Loss: 0.886 | Val accuracy: 0.220\n",
            "Epoch: 03 |Train Loss: 0.985 | Train accuracy: 0.282|Val. Loss: 0.818 | Val accuracy: 0.275\n",
            "Epoch: 04 |Train Loss: 0.881 | Train accuracy: 0.351|Val. Loss: 0.747 | Val accuracy: 0.354\n",
            "Epoch: 05 |Train Loss: 0.780 | Train accuracy: 0.418|Val. Loss: 0.678 | Val accuracy: 0.409\n",
            "Epoch: 06 |Train Loss: 0.697 | Train accuracy: 0.472|Val. Loss: 0.657 | Val accuracy: 0.450\n",
            "Epoch: 07 |Train Loss: 0.632 | Train accuracy: 0.517|Val. Loss: 0.609 | Val accuracy: 0.480\n",
            "Epoch: 08 |Train Loss: 0.578 | Train accuracy: 0.556|Val. Loss: 0.574 | Val accuracy: 0.514\n",
            "Epoch: 09 |Train Loss: 0.533 | Train accuracy: 0.588|Val. Loss: 0.553 | Val accuracy: 0.538\n",
            "Epoch: 10 |Train Loss: 0.494 | Train accuracy: 0.616|Val. Loss: 0.545 | Val accuracy: 0.555\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8e252f6d5d141bba53ec2757bbb498f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.110107…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▃▄▅▆▆▇██</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.6157</td></tr><tr><td>train_loss</td><td>0.49432</td></tr><tr><td>val_accuracy</td><td>0.5555</td></tr><tr><td>val_loss</td><td>0.54452</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">treasured-sweep-4</strong> at: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/9apz8ryn' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/9apz8ryn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230516_143633-9apz8ryn/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z37xno1r with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230516_150033-z37xno1r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/z37xno1r' target=\"_blank\">lucky-sweep-5</a></strong> to <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/z37xno1r' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/z37xno1r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 |Train Loss: 1.240 | Train accuracy: 0.156|Val. Loss: 0.969 | Val accuracy: 0.162\n",
            "Epoch: 02 |Train Loss: 1.093 | Train accuracy: 0.226|Val. Loss: 0.915 | Val accuracy: 0.235\n",
            "Epoch: 03 |Train Loss: 0.981 | Train accuracy: 0.292|Val. Loss: 0.826 | Val accuracy: 0.309\n",
            "Epoch: 04 |Train Loss: 0.864 | Train accuracy: 0.367|Val. Loss: 0.750 | Val accuracy: 0.370\n",
            "Epoch: 05 |Train Loss: 0.762 | Train accuracy: 0.432|Val. Loss: 0.688 | Val accuracy: 0.419\n",
            "Epoch: 06 |Train Loss: 0.681 | Train accuracy: 0.484|Val. Loss: 0.672 | Val accuracy: 0.455\n",
            "Epoch: 07 |Train Loss: 0.617 | Train accuracy: 0.528|Val. Loss: 0.624 | Val accuracy: 0.487\n",
            "Epoch: 08 |Train Loss: 0.563 | Train accuracy: 0.566|Val. Loss: 0.607 | Val accuracy: 0.507\n",
            "Epoch: 09 |Train Loss: 0.519 | Train accuracy: 0.597|Val. Loss: 0.570 | Val accuracy: 0.530\n",
            "Epoch: 10 |Train Loss: 0.486 | Train accuracy: 0.621|Val. Loss: 0.571 | Val accuracy: 0.544\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▅▆▆▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.62129</td></tr><tr><td>train_loss</td><td>0.48576</td></tr><tr><td>val_accuracy</td><td>0.54377</td></tr><tr><td>val_loss</td><td>0.57073</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lucky-sweep-5</strong> at: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/z37xno1r' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/z37xno1r</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230516_150033-z37xno1r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i8us8s8z with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230516_152435-i8us8s8z</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/i8us8s8z' target=\"_blank\">curious-sweep-6</a></strong> to <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/sweeps/t1x3tqqp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/i8us8s8z' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS6910-Assignment3/runs/i8us8s8z</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 |Train Loss: 0.894 | Train accuracy: 0.360|Val. Loss: 0.610 | Val accuracy: 0.470\n",
            "Epoch: 02 |Train Loss: 0.524 | Train accuracy: 0.599|Val. Loss: 0.528 | Val accuracy: 0.558\n",
            "Epoch: 03 |Train Loss: 0.436 | Train accuracy: 0.663|Val. Loss: 0.500 | Val accuracy: 0.592\n",
            "Epoch: 04 |Train Loss: 0.395 | Train accuracy: 0.694|Val. Loss: 0.486 | Val accuracy: 0.611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7ffaa8348280> (for post_run_cell):\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', #grid, random,bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'  \n",
        "    },\n",
        "    'parameters': {\n",
        "        'lr': {\n",
        "            'values': [0.001,0.0001]\n",
        "        },\n",
        "        'layer_size': {\n",
        "            'values': [1,2,3,4]\n",
        "        },        \n",
        "        'cell_type':{\n",
        "            'values':['rnn','lstm','gru']\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0,0.2,0.4,0.6]\n",
        "        },\n",
        "        'hidden_layers':{\n",
        "            'values':[64,128,256]\n",
        "        },\n",
        "        \n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='shreyashgadgil007', project=\"CS6910-Assignment3\")\n",
        "\n",
        "def sweep_train():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults = {\n",
        "      'lr':0.0001,\n",
        "      'layer_size':4,\n",
        "      'cell_type':'lstm',\n",
        "      'dropout':0.4,\n",
        "      'hidden_layers':128,\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(project='CS6910-Assignment3', entity='shreyashgadgil007',config=config_defaults)\n",
        "  wandb.run.name = 'cell:'+ str(wandb.config.cell_type)+' ;lr:'+str(wandb.config.lr)+ ' ;layer_size:'+str(wandb.config.layer_size)+ ' ;dropout:'+str(wandb.config.dropout)+' ;hidden:'+str(wandb.config.hidden_layers)\n",
        "  config = wandb.config\n",
        "  lr = config.lr\n",
        "  layer_size = config.layer_size\n",
        "  cell_type = config.cell_type\n",
        "  hidden_layers = config.hidden_layers  \n",
        "  dropout = config.dropout\n",
        "  # Model training here\n",
        "\n",
        "  input_size_encoder = len(eng_token_map)\n",
        "  output_size=input_size_decoder=len(mar_token_map)\n",
        "\n",
        "  encoder_embedding_size=29\n",
        "  decoder_embedding_size=67\n",
        "  encoder_net=Encoder(input_size_encoder,encoder_embedding_size,hidden_layers,layer_size,cell_type,p=dropout).to(device)\n",
        "  decoder_net=Decoder(input_size_decoder,decoder_embedding_size,hidden_layers,output_size,layer_size,cell_type,p=dropout).to(device)\n",
        "  model=Seq2Seq(encoder_net,decoder_net,cell_type).to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  import math\n",
        "  import time\n",
        " \n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "  model.train()\n",
        "\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "  val_epoch_loss = 0\n",
        "  val_epoch_acc = 0\n",
        "  \n",
        "  N_EPOCHS = 10\n",
        "  CLIP = 1\n",
        "\n",
        "  for epoch in range(N_EPOCHS):\n",
        "\n",
        "  #TRAINING BLOCK\n",
        "    model.train()\n",
        "    for _, (src, trg) in enumerate(train_iter):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg.permute(1,0)\n",
        "        trg = torch.reshape(trg[1:], (-1,))\n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        train_correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        train_epoch_acc += train_correct.sum().item() / len(non_pad_elements)\n",
        "        loss.backward()\n",
        "\n",
        "        #READ IF WE CAN PASS CLIP AS A HYPERPARAMETER \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    train_epoch_loss = train_epoch_loss / len(train_iter)\n",
        "    train_epoch_acc = train_epoch_acc / len(train_iter)\n",
        "\n",
        "\n",
        "    #EVALUATION MODE\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(valid_iter):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg.permute(1,0)\n",
        "            trg = torch.reshape(trg[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            val_epoch_loss += loss.item()\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            val_correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            val_epoch_acc += val_correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "    val_epoch_loss = val_epoch_loss / len(valid_iter)\n",
        "    val_epoch_acc = val_epoch_acc / len(valid_iter)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} |Train Loss: {train_epoch_loss:.3f} | Train accuracy: {train_epoch_acc:.3f}|Val. Loss: {val_epoch_loss:.3f} | Val accuracy: {val_epoch_acc:.3f}')\n",
        "    wandb.log({\"train_loss\":train_epoch_loss,\"train_accuracy\": train_epoch_acc,\"val_loss\":val_epoch_loss,\"val_accuracy\":val_epoch_acc},)\n",
        "    #emptying the cache after one complete run\n",
        "    if epoch==N_EPOCHS-1:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "#RUNNING THE SWEEP\n",
        "wandb.agent(sweep_id, function=sweep_train, count=120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVING OUTPUT IN CSV FILES AND WORD LEVEL ACCURACY CALCULATION"
      ],
      "metadata": {
        "id": "4acZIA2zUmAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing end of sentence token\n",
        "solution_test_att = [word.replace('.', '') for word in solution_test_att]\n",
        "solution_test = [word.replace('.', '') for word in solution_test]\n",
        "def calculate_accuracy(list1, list2):\n",
        "    total_words = len(list1)\n",
        "    correct_words = 0\n",
        "\n",
        "    for word1, word2 in zip(list1, list2):\n",
        "        if word1 == word2:\n",
        "            correct_words += 1\n",
        "\n",
        "    accuracy = correct_words / total_words * 100\n",
        "    return accuracy\n",
        "\n",
        "vanilla_seq2seq_accuracy=calculate_accuracy(test_ma,solution_test)\n",
        "attention_seq2seq_accuracy=calculate_accuracy(test_ma,solution_test_att)\n",
        "print('vanilla_seq2seq_Acc.:',vanilla_seq2seq_accuracy)\n",
        "print('attention_seq2seq_Acc.:',attention_seq2seq_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhc-w20id7NW",
        "outputId": "ccc67f99-5f88-44df-883c-f937d4f7dfb6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vanilla_seq2seq_Acc.: 29.98046875\n",
            "attention_seq2seq_Acc.: 32.3486328125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EPQBda8BrPP3"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Predictions_attention.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the column headers\n",
        "    writer.writerow(['English', 'Marathi_translation', 'Attention_seq2seq_pred'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for row in zip(test_en, test_ma, solution_test_att):\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "njN2lGUV2ptd"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "file_path = '/content/drive/MyDrive/Predictions_vanilla.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the column headers\n",
        "    writer.writerow(['English', 'Marathi_translation', 'Vanilla_seq2seq_pred'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for row in zip(test_en, test_ma, solution_test):\n",
        "        writer.writerow(row)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0029bd3ca1c94350a4ed311349e040bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009d917192ac45f8b9a5cb3e88b3be67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09dc089336be4b8a9fb06ebd4e27b92e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c4c5300439a47fca5d0dc2bbb00c7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e20596ffc514c82b89c308c78e60097": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_009d917192ac45f8b9a5cb3e88b3be67",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99445299e74d4e7db3951662a977c21a",
            "value": 0.11012801204819277
          }
        },
        "2de8fbf1431348c0b375c2bea37bc58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f6b8df6ebb44ab1b38f5aebd30225d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb0c0dc7f564ad5849f01201a2349dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fafea03cb3874a209280303fd0ac44e5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66c1662f065e4171803abdb4210d4df0",
            "value": 1
          }
        },
        "3726b5cd9ab240f198b0abf2bd0ee999": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb5d0076b4e4ce8bf8943a44895bdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee966b1121cd45c28893b2cc3a0f36ef",
              "IPY_MODEL_1e20596ffc514c82b89c308c78e60097"
            ],
            "layout": "IPY_MODEL_09dc089336be4b8a9fb06ebd4e27b92e"
          }
        },
        "3f8878c3e01f4dfe954752b6a726974c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cffdb42030b4aaaa4adf32ed67a4bd0",
            "placeholder": "​",
            "style": "IPY_MODEL_d490c128677e486981c7ed932e7a8e4a",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "3fa2e79d8bf645fd925b2ca74b33ace1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4149a4c78e664d71a256e6deaab7716d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f8878c3e01f4dfe954752b6a726974c",
              "IPY_MODEL_2fb0c0dc7f564ad5849f01201a2349dc"
            ],
            "layout": "IPY_MODEL_3726b5cd9ab240f198b0abf2bd0ee999"
          }
        },
        "4562bbd5ab014f7084a5b74100662d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db95218bd8c45fd8638e73b17655541": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e3528158aaf4a6687bdeb93fd7164d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cffdb42030b4aaaa4adf32ed67a4bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62351b579cad492bafe79bec945e8327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa2e79d8bf645fd925b2ca74b33ace1",
            "placeholder": "​",
            "style": "IPY_MODEL_2de8fbf1431348c0b375c2bea37bc58a",
            "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "62cdf5406f4f4ae0bfef029acc8b25ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0029bd3ca1c94350a4ed311349e040bf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99b20e257eb94f7c9ea138b138b8b92a",
            "value": 1
          }
        },
        "66c1662f065e4171803abdb4210d4df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "770c3cb14d53452296ae96b6d12acb2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99445299e74d4e7db3951662a977c21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99b20e257eb94f7c9ea138b138b8b92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c269d71a857e408aa28d91b2efd35eff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4204db901f44e57a468b949be7a9cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0e13e633f6c46749d354d038df3dfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4562bbd5ab014f7084a5b74100662d6c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e3528158aaf4a6687bdeb93fd7164d3",
            "value": 1
          }
        },
        "d2c4d6f23f594ef3b9bb9514eb986abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62351b579cad492bafe79bec945e8327",
              "IPY_MODEL_62cdf5406f4f4ae0bfef029acc8b25ac"
            ],
            "layout": "IPY_MODEL_770c3cb14d53452296ae96b6d12acb2b"
          }
        },
        "d490c128677e486981c7ed932e7a8e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e252f6d5d141bba53ec2757bbb498f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed6fb297d7cb4188953724e8fd678c56",
              "IPY_MODEL_d0e13e633f6c46749d354d038df3dfff"
            ],
            "layout": "IPY_MODEL_2f6b8df6ebb44ab1b38f5aebd30225d5"
          }
        },
        "ed6fb297d7cb4188953724e8fd678c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db95218bd8c45fd8638e73b17655541",
            "placeholder": "​",
            "style": "IPY_MODEL_c4204db901f44e57a468b949be7a9cc5",
            "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "ee966b1121cd45c28893b2cc3a0f36ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c269d71a857e408aa28d91b2efd35eff",
            "placeholder": "​",
            "style": "IPY_MODEL_1c4c5300439a47fca5d0dc2bbb00c7c5",
            "value": "0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "fafea03cb3874a209280303fd0ac44e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}